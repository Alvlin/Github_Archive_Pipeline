{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bede748b-1c75-4e16-8837-3047ee782151",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./ADLS Setup Variables_SP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e072e38b-f01e-481c-83b9-0931a46aeb5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Imports and Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cff6231f-b8f8-4c8b-9643-6302e73b074a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, day,expr,explode\n",
    "from pyspark.sql.types import BooleanType, StringType, TimestampType, IntegerType, StructType, StructField, LongType\n",
    "import sparknlp\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "\n",
    "from sparknlp import Finisher\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab3f08d8-e519-4a54-b69e-e9981647867b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.format('parquet').load(bronze_path1)\n",
    "df2 = spark.read.format('parquet').load(bronze_path2)\n",
    "df = df1.union(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a394c147-92ee-43b2-b52d-133afd42b587",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####============================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5435e88-4f15-4acd-8e3b-99049f08b02c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Actor Table\n",
    "- Add is_bot column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c0447c4-1a35-48b2-bdc1-1bb13391ae41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "actor_df = (df.select(\n",
    "                \"actor.id\",\n",
    "                \"actor.login\", \n",
    "                \"actor.display_login\")\n",
    "            .dropna(subset=[\"id\"])\n",
    "            .dropDuplicates([\"id\"])                         \n",
    "            .withColumn(\"is_bot\",                        \n",
    "                        when(col(\"login\").contains(\"[bot]\"), True)\n",
    "                        .otherwise(False)) \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f72db3c0-54f2-401c-a1bc-dd06c8ff3644",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('id', LongType(), nullable = False),\n",
    "    StructField('login', StringType(), nullable = False),\n",
    "    StructField('display_login', StringType(), nullable = False),\n",
    "    StructField('is_bot', BooleanType(), nullable = False)\n",
    "])\n",
    "actor_df = spark.createDataFrame(actor_df.rdd, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84097226-54cd-407d-ade8-23a3195e2a1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Actor Table to Storage\n",
    "\n",
    "(actor_df\n",
    " .repartition(2)\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .option(\"header\", True)\n",
    " .mode(\"overwrite\")       \n",
    " .save(silver_path + \"ActorTable\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef64ee06-ceaa-4721-a818-b86b4a1fd46b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Event Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac5100dd-2393-48b2-81f9-2598617ad229",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "event_df = df.select(\n",
    "    col(\"id\").cast(\"long\"),\n",
    "    col(\"type\").alias(\"event_type\"),\n",
    "    col(\"actor.id\").alias(\"actor_id\"),\n",
    "    col(\"repo.id\").alias(\"repo_id\"),\n",
    "    col(\"org.id\").alias(\"org_id\"),\n",
    "    \"public\",\n",
    "    \"created_at\"\n",
    ").dropna(subset=[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340af30e-f079-472d-a971-fc9323263c9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('id', LongType(), nullable = False),\n",
    "    StructField('event_type', StringType(), nullable = False),\n",
    "    StructField('actor_id', LongType(), nullable = True),\n",
    "    StructField('repo_id', LongType(), nullable = False),\n",
    "    StructField('org_id', LongType(), nullable = True),\n",
    "    StructField('public', BooleanType(), nullable = False),\n",
    "    StructField('created_at', TimestampType(), nullable = False)\n",
    "])\n",
    "event_df = spark.createDataFrame(event_df.rdd, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d51fcb29-0ee2-4d43-bd1d-6c683f0f5786",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Event Table to Storage\n",
    "\n",
    "(event_df\n",
    " .repartition(13)\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .option(\"header\", True)\n",
    " .mode(\"overwrite\")       \n",
    " .save(silver_path + \"EventTable\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add55fc2-0fa7-4f71-b9df-534547e9ceae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Org Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18ea270a-9372-4c13-ba7c-b6f2e6b51017",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "org_df = (df.select(\"org.id\", \"org.login\", \"org.url\")\n",
    "          .dropna(subset = [\"id\"])\n",
    "          .dropDuplicates([\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ec8e409-1217-4c3c-9690-3bfe92acb4e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('id', LongType(), nullable = False),\n",
    "    StructField('login', StringType(),),\n",
    "    StructField('url', StringType()),\n",
    "])\n",
    "org_df = spark.createDataFrame(org_df.rdd, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ad665cc-3d68-4634-b39c-5bb6d62f5f0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Org Table to Storage\n",
    "\n",
    "(org_df\n",
    " .repartition(1)\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .option(\"header\", True)\n",
    " .mode(\"overwrite\")       \n",
    " .save(silver_path + \"OrgTable\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1a65673-e3e6-43cc-8b8e-765d0a4b8e06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Repo Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b5a81cf-2a9f-40da-a5d8-582e5f71f951",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "repo_df = (df.select(\"repo.id\", \"repo.name\", \"repo.url\")\n",
    "             .dropDuplicates([\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad501c24-7588-43e3-b3f3-6ad6bdba99d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('id', LongType(), nullable = False),\n",
    "    StructField('name', StringType(),),\n",
    "    StructField('url', StringType(),),\n",
    "])\n",
    "repo_df = spark.createDataFrame(repo_df.rdd, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "707726b4-84da-4b77-a264-d73797c7fa6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Repo Table to Storage\n",
    "\n",
    "(repo_df\n",
    " .repartition(7)\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .option(\"header\", True)\n",
    " .mode(\"overwrite\")       \n",
    " .save(silver_path + \"RepoTable\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3b7c8d3-115c-45cf-8ee4-1cdc2d58b25b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#PushEvent Table\n",
    "\n",
    "- Add is_main column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c37c998-17d5-4278-ac75-47963c1f3fbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "push_event_df = (df.filter(col(\"type\") == \"PushEvent\")\n",
    "                 .select(\n",
    "                     col(\"id\").cast(\"long\").alias(\"event_id\"),\n",
    "                     \"payload.push_id\",\n",
    "                     \"payload.size\",\n",
    "                     \"payload.distinct_size\",\n",
    "                     col(\"payload.ref\").alias(\"branch_ref\"),\n",
    "                     col(\"payload.commits\")[0].sha.alias(\"commit_id\")\n",
    "                     )).dropna(subset = [\"commit_id\"]).withColumn(\n",
    "    \"is_main\",                                                      \n",
    "    when(col(\"branch_ref\").endswith(\"main\"), True)\n",
    "    .when(col(\"branch_ref\").endswith(\"master\"), True)\n",
    "    .otherwise(False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd757a83-e81b-47bf-87d5-f81b786ed57c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('event_id', LongType(), nullable = False),\n",
    "    StructField('push_id', LongType(), nullable = False),\n",
    "    StructField('size', IntegerType(),),\n",
    "    StructField('distinct_size', IntegerType(),),\n",
    "    StructField('branch_ref', StringType(), nullable = False),\n",
    "    StructField('commit_id', StringType(), nullable = False),\n",
    "    StructField('is_main', BooleanType(), nullable = False)\n",
    "])\n",
    "push_event_df = spark.createDataFrame(push_event_df.rdd, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0a0bc2-d1f2-4ed7-976a-041e992b745c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Push Table to Storage\n",
    "\n",
    "(push_event_df\n",
    " .repartition(16)\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .option(\"header\", True)\n",
    " .mode(\"overwrite\")       \n",
    " .save(silver_path + \"PushEventTable\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cf62474-3e31-4737-b973-a7113e3e25f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Commit Table\n",
    "\n",
    "- Optimize Language Detection on Future Sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b620a62-57ef-413c-ae01-baf0a5632716",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "commit_df1 = (df.filter(col(\"type\") == \"PushEvent\").select(\n",
    "    col(\"payload.push_id\").alias(\"commit_id\"),\n",
    "    col(\"payload.commits\")[0].message.alias(\"commit_message\")\n",
    "    ).dropna(subset = [\"commit_message\"])\n",
    "    .filter(col(\"commit_message\").rlike('[a-zA-Z0-9]'))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac09d48f-22c8-401e-a325-08db0d781719",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld_wiki_tatoeba_cnn_43 download started this may take some time.\nApproximate size to download 7.5 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Transforms raw texts to `document` annotation\n",
    "document_assembler = (\n",
    "    DocumentAssembler()\n",
    "    .setInputCol(\"commit_message\")\n",
    "    .setOutputCol(\"document\")\n",
    ")\n",
    "# Step 2: Determines the language of the text\n",
    "languageDetector = (\n",
    "    LanguageDetectorDL.pretrained(\"ld_wiki_tatoeba_cnn_43\")\n",
    "    .setInputCols(\"document\")\n",
    "    .setOutputCol(\"lang\")\n",
    "    .setThreshold(0.6) \n",
    ")\n",
    "\n",
    "finisher = Finisher().setInputCols([\"lang\"]).setIncludeMetadata(False)\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[document_assembler, languageDetector, finisher])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dec299c7-a59d-474e-8df4-bea94cdaacc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = nlpPipeline.fit(commit_df1).transform(commit_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d43d5bc6-413f-484b-a5c3-188d3b7c54b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "commit_df = result.select(\n",
    "    \"commit_id\",\n",
    "    col(\"finished_lang\")[0].alias(\"language\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a4b0ad4-0e42-4e33-8b1e-b6c8411c87fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Commit Table to Storage\n",
    "\n",
    "(commit_df\n",
    " .repartition(16)\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .option(\"header\", True)\n",
    " .mode(\"overwrite\")       \n",
    " .save(silver_path + \"CommitTable\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d40e3258-c405-4fdc-bb5d-f511009f49b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Team 4 Silver Medallion Notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
